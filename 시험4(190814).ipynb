{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시험4(190814)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 다음과 같은 어레이를 Numpy를 이용하여 만드시오.\n",
    "### 1-1 [0., 0.5, 1., 1.5, 2., 2.5, 3., 3.5, 4., 4.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 5, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2 [[1, 2, 3, 4, 5],\n",
    "   ### [6, 7, 8, 9, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1, 11).reshape(2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3 [[1, 0, 0],\n",
    "### [0, 1, 0],\n",
    "### [0, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]], dtype=int8)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.identity(n=3, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4 [[1, 1, 1, 1],\n",
    "### [1, 1, 1, 1],\n",
    "### [1, 1, 1, 1],\n",
    "### [1, 1, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((4,4), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-5 [[1, 3, 5, 7],\n",
    "### [9, 11, 13, 15],\n",
    "### [17, 19, 21, 23]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3,  5,  7],\n",
       "       [ 9, 11, 13, 15],\n",
       "       [17, 19, 21, 23]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1, 24, 2).reshape(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 다음과 같은 데이터프레임을 만드시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>지역</th>\n",
       "      <th>2015</th>\n",
       "      <th>2010</th>\n",
       "      <th>2005</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010-2015 증가율</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>서울</th>\n",
       "      <td>수도권</td>\n",
       "      <td>9904312</td>\n",
       "      <td>9631482</td>\n",
       "      <td>9762546</td>\n",
       "      <td>9853972</td>\n",
       "      <td>0.0283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>부산</th>\n",
       "      <td>경상권</td>\n",
       "      <td>3448737</td>\n",
       "      <td>3393191</td>\n",
       "      <td>3512547</td>\n",
       "      <td>3655437</td>\n",
       "      <td>0.0163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>인천</th>\n",
       "      <td>수도권</td>\n",
       "      <td>2890451</td>\n",
       "      <td>2632035</td>\n",
       "      <td>2517680</td>\n",
       "      <td>2466338</td>\n",
       "      <td>0.0982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>대구</th>\n",
       "      <td>경상권</td>\n",
       "      <td>2466052</td>\n",
       "      <td>2431774</td>\n",
       "      <td>2456016</td>\n",
       "      <td>2473990</td>\n",
       "      <td>0.0141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     지역     2015     2010     2005     2000  2010-2015 증가율\n",
       "서울  수도권  9904312  9631482  9762546  9853972         0.0283\n",
       "부산  경상권  3448737  3393191  3512547  3655437         0.0163\n",
       "인천  수도권  2890451  2632035  2517680  2466338         0.0982\n",
       "대구  경상권  2466052  2431774  2456016  2473990         0.0141"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"2015\": [9904312, 3448737, 2890451, 2466052],\n",
    "    \"2010\": [9631482, 3393191, 2632035, 2431774],\n",
    "    \"2005\": [9762546, 3512547, 2517680, 2456016],\n",
    "    \"2000\": [9853972, 3655437, 2466338, 2473990],\n",
    "    \"지역\": [\"수도권\", \"경상권\", \"수도권\", \"경상권\"],\n",
    "    \"2010-2015 증가율\": [0.0283, 0.0163, 0.0982, 0.0141]\n",
    "}\n",
    "columns = [\"지역\", \"2015\", \"2010\", \"2005\", \"2000\", \"2010-2015 증가율\"]\n",
    "index = [\"서울\", \"부산\", \"인천\", \"대구\"]\n",
    "df = pd.DataFrame(data, index=index, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 타이타닉호 승객에 대해서 다음을 구하시오.\n",
    "### 3-1 성별(sex) 인원수, 선실별(class) 인원수, 사망/생존(alive) 인원수를 구하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "titanic = sns.load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0    30\n",
       "22.0    27\n",
       "18.0    26\n",
       "19.0    25\n",
       "30.0    25\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.age.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Third     491\n",
       "First     216\n",
       "Second    184\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     549\n",
       "yes    342\n",
       "Name: alive, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.alive.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2 '미성년자', '청년', '중년', '장년', '노년' 승객의 비율을 구하시오. 단 나이의 기준은 [1, 15, 30, 45, 60, 99] 임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [1, 15, 30, 45, 60, 99]\n",
    "labels = [\"미성년자\", \"청년\", \"중년\", \"장년\", \"노년\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_alive = titanic[titanic.survived == 1]['age']\n",
    "titanic_dead = titanic[titanic.survived == 0]['age']\n",
    "alive_ = pd.cut(titanic_alive, bins, labels=labels)\n",
    "alive_.dropna(inplace = True)\n",
    "dead_ = pd.cut(titanic_dead, bins, labels=labels)\n",
    "dead_.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "청년      0.420863\n",
       "중년      0.309353\n",
       "미성년자    0.133094\n",
       "장년      0.118705\n",
       "노년      0.017986\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(alive_)/sum(pd.value_counts(alive_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "청년      0.495261\n",
       "중년      0.274882\n",
       "장년      0.113744\n",
       "미성년자    0.075829\n",
       "노년      0.040284\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(dead_)/sum(pd.value_counts(dead_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 팁 데이터에 대해서 다음을 구하시오\n",
    "### 4-1 팁의 비율(단위 %)을 소숫점 2째자리까지 구하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset(\"tips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>tip_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>29.03</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "      <td>20.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>27.18</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>7.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>22.67</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>8.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>17.82</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>9.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>18.78</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>15.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_bill   tip     sex smoker   day    time  size  tip_pct\n",
       "239       29.03  5.92    Male     No   Sat  Dinner     3    20.39\n",
       "240       27.18  2.00  Female    Yes   Sat  Dinner     2     7.36\n",
       "241       22.67  2.00    Male    Yes   Sat  Dinner     2     8.82\n",
       "242       17.82  1.75    Male     No   Sat  Dinner     2     9.82\n",
       "243       18.78  3.00  Female     No  Thur  Dinner     2    15.97"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips['tip_pct'] = (tips['tip'] / tips['total_bill'] * 100).round(2)\n",
    "tips.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2 팁의 비율이 가장 높은 날은 목, 금, 토, 일요일 중 어떤 날인지 피봇 테이블을 이용하여 구하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>tip_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>29.03</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "      <td>20.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>27.18</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>7.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>22.67</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>8.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>17.82</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>9.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>18.78</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>15.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_bill   tip     sex smoker   day    time  size  tip_pct\n",
       "239       29.03  5.92    Male     No   Sat  Dinner     3    20.39\n",
       "240       27.18  2.00  Female    Yes   Sat  Dinner     2     7.36\n",
       "241       22.67  2.00    Male    Yes   Sat  Dinner     2     8.82\n",
       "242       17.82  1.75    Male     No   Sat  Dinner     2     9.82\n",
       "243       18.78  3.00  Female     No  Thur  Dinner     2    15.97"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "tips['tip_pct'] = (tips['tip'] / tips['total_bill'] * 100).round(2)\n",
    "tips.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tip_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Thur</th>\n",
       "      <td>16.126452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fri</th>\n",
       "      <td>16.991579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sat</th>\n",
       "      <td>15.314598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sun</th>\n",
       "      <td>16.689605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tip_pct\n",
       "day            \n",
       "Thur  16.126452\n",
       "Fri   16.991579\n",
       "Sat   15.314598\n",
       "Sun   16.689605"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips.pivot_table('tip_pct','day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 다음의 지시대로 SQLite3를 이용하는 파이썬 프로그램을 작성하시오.\n",
    "### 5-1 필드로 [백넘버(PK), 이름, 포지션]을 갖는 테이블 Eagles를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nconn = sqlite3.connect(':memory:')    # 메모리 DB 접속(일회성)\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect('./test.db') \n",
    "'''\n",
    "conn = sqlite3.connect(':memory:')    # 메모리 DB 접속(일회성)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0xb48f0a0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute('CREATE TABLE IF NOT EXISTS Eagles \\\n",
    "    (back_no INT NOT NULL, \\\n",
    "     name TEXT, \\\n",
    "     position TEXT, \\\n",
    "     PRIMARY KEY(back_no));')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2 1)번에서 만든 테이블에 (8, 정근우, 내야수)를 포함하여 임의로 5명의 선수를 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0xb48fab0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"INSERT INTO Eagles VALUES \\\n",
    "    (8, '정근우', '내야수'), \\\n",
    "    (1, '하주석', '내야수'), \\\n",
    "    (52, '김태균', '내야수'), \\\n",
    "    (30, '호잉', '외야수'), \\\n",
    "    (28, '양성우', '외야수');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-3 2)번에서 입력한 선수 모두를 보여주는 프로그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, '정근우', '내야수')\n",
      "(1, '하주석', '내야수')\n",
      "(52, '김태균', '내야수')\n",
      "(30, '호잉', '외야수')\n",
      "(28, '양성우', '외야수')\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute('SELECT * FROM Eagles')\n",
    "for row in cur:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-4 정근우 선수의 포지션을 외야수로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, '정근우', '외야수')\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "sql = \"UPDATE Eagles SET position='외야수' WHERE back_no=8;\"\n",
    "cur.execute(sql)\n",
    "conn.commit()\n",
    "\n",
    "sql = 'SELECT * FROM Eagles WHERE back_no=8;'\n",
    "cur.execute(sql)\n",
    "row = cur.fetchone()\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-5 5명의 선수중 백넘버가 가장 큰 선수를 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "sql = 'SELECT back_no FROM Eagles ORDER BY back_no DESC LIMIT 1;'\n",
    "cur.execute(sql)\n",
    "max_no = cur.fetchone()\n",
    "max_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 시그모이드 함수 (sigmoid(x) = 1 / (1 + np.exp(-x)))와 시그모이드 함수를 미분한 함수(sigmoid(x) * (1 - sigmoid(x))의 그래프를 그리시오.(단, x의 범위는 -3에서 +3까지))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "def deri_sig(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-3, 3, 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivative_Y = derivative_sigmoid(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, sig_Y, color='b')\n",
    "plt.plot(X, derivative_Y, color='r')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 다음의 빈 칸에 들어갈 말은?\n",
    "### 7-1 밥그릇 모양의 그래프에서 경사도를 따라 움직이면서 기울기가 0이되는 지점을 찾는 것을 ( 경사하강법 ) 이라 한다.\n",
    "### 7-2 1)에서 이동 거리를 정해 주는 것은 ( 학습률 ) 이다.\n",
    "### 7-3 인공지능에서 신경망을 이루는 가장 중요한 기본 단위는 ( 퍼셉트론 ) 이다.\n",
    "### 7-4 활성화 함수로서 x가 음수일 경우에는 0, x가 0 이상일 때는 x 값을 갖는 함수는 ( 시그모이드 함수 ) 이다.\n",
    "### 7-5 딥 러닝에서 입력층과 출력층 사이의 층을 ( 은닉층 ) 이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 아이리스 데이터의 4가지 속성(꽃받침 길이/폭, 꽃잎 길이/폭)을 이용하여 품종을 예측(단, 정확도는 98% 이상일 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = sns.load_dataset(\"iris\")\n",
    "iris.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "dataset = iris.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "Y_obj = dataset[:,4]\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "Y = np_utils.to_categorical(Y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "seed = 0\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=4, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# 모델 컴파일 \n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.2086 - acc: 0.3333\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.9764 - acc: 0.3333\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.8204 - acc: 0.4000\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.7408 - acc: 0.6600\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.6729 - acc: 0.6867\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.6370 - acc: 0.6733\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.5729 - acc: 0.8733\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.5401 - acc: 0.8800\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.5019 - acc: 0.9000\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.4733 - acc: 0.9400\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.4497 - acc: 0.9067\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.4305 - acc: 0.9467\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.4090 - acc: 0.9533\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.3925 - acc: 0.9600\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.3752 - acc: 0.9533\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.3587 - acc: 0.9533\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.3484 - acc: 0.9400\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.3312 - acc: 0.9667\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.3224 - acc: 0.9800\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.3100 - acc: 0.9667\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.3011 - acc: 0.9600\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.2921 - acc: 0.9733\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.2812 - acc: 0.9800\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.2741 - acc: 0.9667\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.2621 - acc: 0.9800\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2549 - acc: 0.9800\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.2472 - acc: 0.9600\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.2388 - acc: 0.9667\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.2323 - acc: 0.9800\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.2277 - acc: 0.9667\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2173 - acc: 0.9800\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.2100 - acc: 0.9800\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2080 - acc: 0.9733\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.2015 - acc: 0.9733\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1918 - acc: 0.9800\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1876 - acc: 0.9800\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1875 - acc: 0.9733\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.1819 - acc: 0.9667\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1740 - acc: 0.9800\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1703 - acc: 0.9800\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.1692 - acc: 0.9667\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1614 - acc: 0.9667\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1583 - acc: 0.9800\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1555 - acc: 0.9800\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1506 - acc: 0.9800\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1488 - acc: 0.9800\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1441 - acc: 0.9733\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1440 - acc: 0.9800\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1399 - acc: 0.9733\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1369 - acc: 0.9800\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1326 - acc: 0.9800\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1317 - acc: 0.9733\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1289 - acc: 0.9800\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.1258 - acc: 0.9800\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1258 - acc: 0.9733\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.1249 - acc: 0.9733\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1238 - acc: 0.9733\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1184 - acc: 0.9733\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1201 - acc: 0.9733\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1218 - acc: 0.9600\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1159 - acc: 0.9733\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1129 - acc: 0.9667\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1140 - acc: 0.9800\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.1127 - acc: 0.9667\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1088 - acc: 0.9733\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1101 - acc: 0.9667\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1051 - acc: 0.9733\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1045 - acc: 0.9800\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1042 - acc: 0.9667\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1026 - acc: 0.9733\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1016 - acc: 0.9733\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1004 - acc: 0.9733\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1007 - acc: 0.9733\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0984 - acc: 0.9733\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.0961 - acc: 0.9800\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.0974 - acc: 0.9733\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0984 - acc: 0.9667\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0968 - acc: 0.9667\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.1015 - acc: 0.9600\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.0927 - acc: 0.9733\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0918 - acc: 0.9733\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0961 - acc: 0.9667\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0998 - acc: 0.9733\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 60us/step - loss: 0.0921 - acc: 0.9667\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0893 - acc: 0.9733\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0880 - acc: 0.9800\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0893 - acc: 0.9667\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.0877 - acc: 0.9733\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0870 - acc: 0.9733\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0887 - acc: 0.9800\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.0869 - acc: 0.9667\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0853 - acc: 0.9800\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.0874 - acc: 0.9733\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.0833 - acc: 0.9733\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0855 - acc: 0.9733\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.0837 - acc: 0.9733\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0843 - acc: 0.9800\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.0857 - acc: 0.9667\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.0826 - acc: 0.9800\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.0847 - acc: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143456d8>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 실행\n",
    "model.fit(X, Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 407us/step\n",
      "\n",
      " Accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 피마 인디언 데이터의 8가지 속성을 이용하여 당뇨병 여부를 판단할 것(단, 데이터의 25%는 테스트 데이터로 사용하여 정확도를 구할 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>plasma</th>\n",
       "      <th>pressure</th>\n",
       "      <th>thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  plasma  pressure  thickness  insulin   BMI  pedigree  age  class\n",
       "0         6     148        72         35        0  33.6     0.627   50      1\n",
       "1         1      85        66         29        0  26.6     0.351   31      0\n",
       "2         8     183        64          0        0  23.3     0.672   32      1\n",
       "3         1      89        66         23       94  28.1     0.167   21      0\n",
       "4         0     137        40         35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:/Workspace/Deep-Learning/dataset/pima-indians-diabetes.csv',\n",
    "                 names = [\"pregnant\", \"plasma\", \"pressure\", \"thickness\",  \n",
    "                 \"insulin\", \"BMI\", \"pedigree\", \"age\", \"class\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dataset = np.loadtxt(\"D:/Workspace/Deep-Learning/dataset/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25,\n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "576/576 [==============================] - 0s 451us/step - loss: 2.6587 - acc: 0.4392\n",
      "Epoch 2/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.9885 - acc: 0.6337\n",
      "Epoch 3/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.8761 - acc: 0.6580\n",
      "Epoch 4/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.8192 - acc: 0.6285\n",
      "Epoch 5/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.7707 - acc: 0.6250\n",
      "Epoch 6/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.7367 - acc: 0.6111\n",
      "Epoch 7/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.7119 - acc: 0.6337\n",
      "Epoch 8/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.6766 - acc: 0.6372\n",
      "Epoch 9/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.6439 - acc: 0.6580\n",
      "Epoch 10/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.6330 - acc: 0.6441\n",
      "Epoch 11/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.6136 - acc: 0.6597\n",
      "Epoch 12/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.6278 - acc: 0.6285\n",
      "Epoch 13/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6241 - acc: 0.6510\n",
      "Epoch 14/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6100 - acc: 0.6406\n",
      "Epoch 15/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.6167 - acc: 0.6719\n",
      "Epoch 16/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6121 - acc: 0.6771\n",
      "Epoch 17/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.6036 - acc: 0.6875\n",
      "Epoch 18/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.6078 - acc: 0.6563\n",
      "Epoch 19/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.6026 - acc: 0.6510\n",
      "Epoch 20/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.6015 - acc: 0.6649\n",
      "Epoch 21/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.6174 - acc: 0.6563\n",
      "Epoch 22/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5914 - acc: 0.6736\n",
      "Epoch 23/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5975 - acc: 0.6719\n",
      "Epoch 24/200\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.5855 - acc: 0.6771\n",
      "Epoch 25/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5890 - acc: 0.6910\n",
      "Epoch 26/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5889 - acc: 0.6962\n",
      "Epoch 27/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5789 - acc: 0.6701\n",
      "Epoch 28/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5825 - acc: 0.6927\n",
      "Epoch 29/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5855 - acc: 0.6892\n",
      "Epoch 30/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5793 - acc: 0.6840\n",
      "Epoch 31/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5747 - acc: 0.6892\n",
      "Epoch 32/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5876 - acc: 0.6944\n",
      "Epoch 33/200\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.5869 - acc: 0.6788\n",
      "Epoch 34/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5736 - acc: 0.6927\n",
      "Epoch 35/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5799 - acc: 0.6979\n",
      "Epoch 36/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5663 - acc: 0.7014\n",
      "Epoch 37/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5719 - acc: 0.6858\n",
      "Epoch 38/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5632 - acc: 0.7188\n",
      "Epoch 39/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5674 - acc: 0.7031\n",
      "Epoch 40/200\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.5667 - acc: 0.7014\n",
      "Epoch 41/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5618 - acc: 0.7049\n",
      "Epoch 42/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5703 - acc: 0.7101\n",
      "Epoch 43/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5726 - acc: 0.6840\n",
      "Epoch 44/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5641 - acc: 0.6910\n",
      "Epoch 45/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5647 - acc: 0.6944\n",
      "Epoch 46/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5516 - acc: 0.7170\n",
      "Epoch 47/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5521 - acc: 0.7135\n",
      "Epoch 48/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5456 - acc: 0.7153\n",
      "Epoch 49/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5641 - acc: 0.7066\n",
      "Epoch 50/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5548 - acc: 0.7083\n",
      "Epoch 51/200\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.5540 - acc: 0.7188\n",
      "Epoch 52/200\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.5546 - acc: 0.7257\n",
      "Epoch 53/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5612 - acc: 0.6962\n",
      "Epoch 54/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5483 - acc: 0.7101\n",
      "Epoch 55/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5618 - acc: 0.7205\n",
      "Epoch 56/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5630 - acc: 0.7135\n",
      "Epoch 57/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5471 - acc: 0.7135\n",
      "Epoch 58/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5455 - acc: 0.7118\n",
      "Epoch 59/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5485 - acc: 0.7170\n",
      "Epoch 60/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5530 - acc: 0.6927\n",
      "Epoch 61/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5432 - acc: 0.7135\n",
      "Epoch 62/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5518 - acc: 0.7083\n",
      "Epoch 63/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5626 - acc: 0.7083\n",
      "Epoch 64/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5416 - acc: 0.7153\n",
      "Epoch 65/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5514 - acc: 0.7153\n",
      "Epoch 66/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5352 - acc: 0.7153\n",
      "Epoch 67/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5425 - acc: 0.7153\n",
      "Epoch 68/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5539 - acc: 0.6997\n",
      "Epoch 69/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5458 - acc: 0.7101\n",
      "Epoch 70/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5563 - acc: 0.7066\n",
      "Epoch 71/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5575 - acc: 0.7118\n",
      "Epoch 72/200\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.5638 - acc: 0.7118\n",
      "Epoch 73/200\n",
      "576/576 [==============================] - 0s 66us/step - loss: 0.5479 - acc: 0.7222\n",
      "Epoch 74/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5316 - acc: 0.7361\n",
      "Epoch 75/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5427 - acc: 0.7413\n",
      "Epoch 76/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5356 - acc: 0.7396\n",
      "Epoch 77/200\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.5553 - acc: 0.7153\n",
      "Epoch 78/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5288 - acc: 0.7170\n",
      "Epoch 79/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5338 - acc: 0.7222\n",
      "Epoch 80/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5444 - acc: 0.7188\n",
      "Epoch 81/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5585 - acc: 0.7222\n",
      "Epoch 82/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5374 - acc: 0.7344\n",
      "Epoch 83/200\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.5298 - acc: 0.7448\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 61us/step - loss: 0.5410 - acc: 0.7170\n",
      "Epoch 85/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5284 - acc: 0.7465\n",
      "Epoch 86/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5308 - acc: 0.7396\n",
      "Epoch 87/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5348 - acc: 0.7222\n",
      "Epoch 88/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5219 - acc: 0.7222\n",
      "Epoch 89/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5227 - acc: 0.7240\n",
      "Epoch 90/200\n",
      "576/576 [==============================] - 0s 64us/step - loss: 0.5232 - acc: 0.7257\n",
      "Epoch 91/200\n",
      "576/576 [==============================] - 0s 69us/step - loss: 0.5235 - acc: 0.7361\n",
      "Epoch 92/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5268 - acc: 0.7431\n",
      "Epoch 93/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5199 - acc: 0.7378\n",
      "Epoch 94/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5221 - acc: 0.7326\n",
      "Epoch 95/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5177 - acc: 0.7274\n",
      "Epoch 96/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5272 - acc: 0.7240\n",
      "Epoch 97/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5234 - acc: 0.7378\n",
      "Epoch 98/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5116 - acc: 0.7431\n",
      "Epoch 99/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5147 - acc: 0.7396\n",
      "Epoch 100/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5091 - acc: 0.7396\n",
      "Epoch 101/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5239 - acc: 0.7326\n",
      "Epoch 102/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5339 - acc: 0.7222\n",
      "Epoch 103/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5173 - acc: 0.7344\n",
      "Epoch 104/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5160 - acc: 0.7396\n",
      "Epoch 105/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5235 - acc: 0.7378\n",
      "Epoch 106/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5182 - acc: 0.7483\n",
      "Epoch 107/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5163 - acc: 0.7413\n",
      "Epoch 108/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5148 - acc: 0.7465\n",
      "Epoch 109/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5185 - acc: 0.7500\n",
      "Epoch 110/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5063 - acc: 0.7465\n",
      "Epoch 111/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5397 - acc: 0.7014\n",
      "Epoch 112/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5111 - acc: 0.7448\n",
      "Epoch 113/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5213 - acc: 0.7431\n",
      "Epoch 114/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5316 - acc: 0.7344\n",
      "Epoch 115/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5138 - acc: 0.7274\n",
      "Epoch 116/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5062 - acc: 0.7448\n",
      "Epoch 117/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5091 - acc: 0.7448\n",
      "Epoch 118/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5114 - acc: 0.7361\n",
      "Epoch 119/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5103 - acc: 0.7396\n",
      "Epoch 120/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5088 - acc: 0.7344\n",
      "Epoch 121/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5264 - acc: 0.7309\n",
      "Epoch 122/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5099 - acc: 0.7622\n",
      "Epoch 123/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5213 - acc: 0.7378\n",
      "Epoch 124/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5189 - acc: 0.7309\n",
      "Epoch 125/200\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.5115 - acc: 0.7378\n",
      "Epoch 126/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5194 - acc: 0.7517\n",
      "Epoch 127/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5099 - acc: 0.7448\n",
      "Epoch 128/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5040 - acc: 0.7413\n",
      "Epoch 129/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5148 - acc: 0.7448\n",
      "Epoch 130/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5002 - acc: 0.7448\n",
      "Epoch 131/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5015 - acc: 0.7604\n",
      "Epoch 132/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5097 - acc: 0.7326\n",
      "Epoch 133/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5016 - acc: 0.7535\n",
      "Epoch 134/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5025 - acc: 0.7483\n",
      "Epoch 135/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5093 - acc: 0.7326\n",
      "Epoch 136/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5213 - acc: 0.7378\n",
      "Epoch 137/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4982 - acc: 0.7535\n",
      "Epoch 138/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4976 - acc: 0.7431\n",
      "Epoch 139/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.5034 - acc: 0.7535\n",
      "Epoch 140/200\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4970 - acc: 0.7587\n",
      "Epoch 141/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5048 - acc: 0.7413\n",
      "Epoch 142/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5076 - acc: 0.7413\n",
      "Epoch 143/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4907 - acc: 0.7569\n",
      "Epoch 144/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5214 - acc: 0.7326\n",
      "Epoch 145/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.5172 - acc: 0.7344\n",
      "Epoch 146/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5065 - acc: 0.7500\n",
      "Epoch 147/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.5091 - acc: 0.7396\n",
      "Epoch 148/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4928 - acc: 0.7587\n",
      "Epoch 149/200\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4931 - acc: 0.7639\n",
      "Epoch 150/200\n",
      "576/576 [==============================] - 0s 68us/step - loss: 0.4994 - acc: 0.7517\n",
      "Epoch 151/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.5017 - acc: 0.7517\n",
      "Epoch 152/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4921 - acc: 0.7726\n",
      "Epoch 153/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4953 - acc: 0.7535\n",
      "Epoch 154/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4917 - acc: 0.7604\n",
      "Epoch 155/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4842 - acc: 0.7708\n",
      "Epoch 156/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.5006 - acc: 0.7587\n",
      "Epoch 157/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4898 - acc: 0.7569\n",
      "Epoch 158/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4814 - acc: 0.7552\n",
      "Epoch 159/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4909 - acc: 0.7569\n",
      "Epoch 160/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4852 - acc: 0.7760\n",
      "Epoch 161/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4881 - acc: 0.7465\n",
      "Epoch 162/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4998 - acc: 0.7500\n",
      "Epoch 163/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4957 - acc: 0.7569\n",
      "Epoch 164/200\n",
      "576/576 [==============================] - 0s 63us/step - loss: 0.4828 - acc: 0.7708\n",
      "Epoch 165/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4888 - acc: 0.7639\n",
      "Epoch 166/200\n",
      "576/576 [==============================] - 0s 61us/step - loss: 0.4806 - acc: 0.7656\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 0s 59us/step - loss: 0.4952 - acc: 0.7535\n",
      "Epoch 168/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4815 - acc: 0.7639\n",
      "Epoch 169/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4862 - acc: 0.7569\n",
      "Epoch 170/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4790 - acc: 0.7639\n",
      "Epoch 171/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4768 - acc: 0.7726\n",
      "Epoch 172/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4783 - acc: 0.7760\n",
      "Epoch 173/200\n",
      "576/576 [==============================] - 0s 59us/step - loss: 0.4797 - acc: 0.7812\n",
      "Epoch 174/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4805 - acc: 0.7743\n",
      "Epoch 175/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4776 - acc: 0.7778\n",
      "Epoch 176/200\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4839 - acc: 0.7674\n",
      "Epoch 177/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4925 - acc: 0.7865\n",
      "Epoch 178/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4827 - acc: 0.7674\n",
      "Epoch 179/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4826 - acc: 0.7622\n",
      "Epoch 180/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4888 - acc: 0.7604\n",
      "Epoch 181/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4847 - acc: 0.7726\n",
      "Epoch 182/200\n",
      "576/576 [==============================] - 0s 54us/step - loss: 0.4848 - acc: 0.7674\n",
      "Epoch 183/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4775 - acc: 0.7726\n",
      "Epoch 184/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4768 - acc: 0.7604\n",
      "Epoch 185/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4764 - acc: 0.7587\n",
      "Epoch 186/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4750 - acc: 0.7691\n",
      "Epoch 187/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4831 - acc: 0.7500\n",
      "Epoch 188/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4760 - acc: 0.7812\n",
      "Epoch 189/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4804 - acc: 0.7656\n",
      "Epoch 190/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4745 - acc: 0.7778\n",
      "Epoch 191/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4751 - acc: 0.7622\n",
      "Epoch 192/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4916 - acc: 0.7500\n",
      "Epoch 193/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4831 - acc: 0.7674\n",
      "Epoch 194/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4713 - acc: 0.7604\n",
      "Epoch 195/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4802 - acc: 0.7656\n",
      "Epoch 196/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4997 - acc: 0.7587\n",
      "Epoch 197/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4786 - acc: 0.7674\n",
      "Epoch 198/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4680 - acc: 0.7743\n",
      "Epoch 199/200\n",
      "576/576 [==============================] - 0s 57us/step - loss: 0.4686 - acc: 0.7778\n",
      "Epoch 200/200\n",
      "576/576 [==============================] - 0s 56us/step - loss: 0.4736 - acc: 0.7760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x149c7320>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 0s 425us/step\n",
      "\n",
      " Accuracy: 0.7708\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
